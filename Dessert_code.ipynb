{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dessert_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EziamaUgonna/Bayesian_analysis-/blob/master/Dessert_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gZWe2bxjksE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install packages\n",
        "#!pip install tensorflow==2.0.0-beta1\n",
        "#!pip install tensorflow_addons as tfa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZkJ7YrjnnoQ",
        "colab_type": "code",
        "outputId": "f2e52bda-7a3d-42ed-8e7e-0b2c294c322d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "try:\n",
        "  # % tensorflow_version only exist in colab\n",
        "  %tensorflow_version 2.\n",
        "except Exception:\n",
        "   pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNbXNLgbkMgs",
        "colab_type": "code",
        "outputId": "9010076e-710f-43f5-84be-dfd7b1ac72b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#import vaex\n",
        "#from sklearn.dummy import DummyRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "import tensorflow as tf\n",
        "#import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "from tensorflow_probability.python.math import random_rademacher\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.layers import ReLU, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Settings\n",
        "sns.set()\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "np.random.seed(12345)\n",
        "#tf.random.set_seed(12345)\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD3bi9lwrtrc",
        "colab_type": "code",
        "outputId": "51103daa-9305-400b-c5b8-dea37618c82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HspOjJKysLdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f_8CYiCtWCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the dataset\n",
        "\"\"\"df = pd.read_csv('/content/gdrive/My Drive/work2.csv').astype(np.float32)\n",
        "df.columns = ['RxDevice', 'FileID', 'TxDevice', 'Gentime', 'TxRandom', 'MsgCount',\n",
        "       'Dsecond', 'Latitude', 'Longitude', 'Elevation', 'Speed', 'Heading',\n",
        "       'Ax', 'Ay', 'Az', 'Yawrate', 'PathCount', 'RadiusOfCurve', 'Confidence']\n",
        "change = df.query('Speed>0').sample(frac = .1).index\n",
        "df.loc[change, 'Speed'] = 0\n",
        "df.loc[change, 'Class'] = 0\n",
        "df.to_csv('work2.csv', header = True, index =False)\n",
        "df.isnull().values.any() , df.isnull().sum(),df.shape\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DCUV2kqj6iE",
        "colab_type": "code",
        "outputId": "e8b92387-4f1a-4ed5-e37a-49962160bc1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1 = pd.read_csv('/content/drive/My Drive/Sensor1_values_bias_0_1_dur_10_dep.csv').astype(np.float32)\n",
        "df2 = pd.read_csv('/content/drive/My Drive/Ground_truth_bias_0_1_dur_10_sensor1_dep.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5d8b0b2a33f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Sensor1_values_bias_0_1_dur_10_dep.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Ground_truth_bias_0_1_dur_10_sensor1_dep.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4UKLDmtsYJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = df.iloc[:,:-1].values\n",
        "#y = df.iloc[:,-1].values\n",
        "X = df1.values\n",
        "y = df2.values\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIa_a-RYsd2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_full, X_test,y_train_full,y_test = train_test_split(X, y, test_size=0.2, random_state=200)\n",
        "X_train, X_valid, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=1)\n",
        "#reshape y-data to become column vector \n",
        "y_train = np.reshape(y_train,[-1,1])\n",
        "y_val   = np.reshape(y_val,[-1,1])\n",
        "y_test  = np.reshape(y_test,[-1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96_jm9Ft0UAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardize the dataset \n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7C--44ApCqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vanilla Neural Network\n",
        "# Batch size\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "# Number of training epochs\n",
        "EPOCHS = 100\n",
        "\n",
        "# Learning rate\n",
        "L_RATE = 1e-4\n",
        "\n",
        "# Proportion of samples to hold out\n",
        "VAL_SPLIT = 0.2\n",
        "training_steps = 2000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tRrHUhglnRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train)).shuffle(1000).repeat(3).batch(7)\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((X_valid_scaled,y_val)).shuffle(1000).repeat(3).batch(7)\n",
        "test_data = tf.data.Dataset.from_tensor_slices((X_test_scaled,y_test)).shuffle(1000).repeat(3).batch(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmi7iSBFqVc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xavier initializer\n",
        "def xavier(shape):\n",
        "    return tf.random.truncated_normal(\n",
        "        shape, \n",
        "        mean=0.0,\n",
        "        stddev=np.sqrt(2/sum(shape)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyrpaymgzvaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BayesianDenseLayer(tf.keras.Model):\n",
        "        \n",
        "    def __init__(self, d_in, d_out, name=None):\n",
        "        \n",
        "        super(BayesianDenseLayer, self).__init__(name=name)\n",
        "        self.d_in = d_in\n",
        "        self.d_out = d_out\n",
        "        \n",
        "        self.w_loc = tf.Variable(xavier([d_in, d_out]), name='w_loc')\n",
        "        self.w_std = tf.Variable(xavier([d_in, d_out])-6.0, name='w_std')\n",
        "        self.b_loc = tf.Variable(xavier([1, d_out]), name='b_loc')\n",
        "        self.b_std = tf.Variable(xavier([1, d_out])-6.0, name='b_std')\n",
        "    \n",
        "    \n",
        "    def call(self, x, sampling=True):\n",
        "        \"\"\"Perform the forward pass\"\"\"\n",
        "        \n",
        "        if sampling:\n",
        "        \n",
        "            # Flipout-estimated weight samples\n",
        "            s = random_rademacher(tf.shape(x))\n",
        "            r = random_rademacher([x.shape[0], self.d_out])\n",
        "            w_samples = tf.nn.softplus(self.w_std)*tf.random.normal([self.d_in, self.d_out])\n",
        "            w_perturbations = r*tf.matmul(x*s, w_samples)\n",
        "            w_outputs = tf.matmul(x, self.w_loc) + w_perturbations\n",
        "            \n",
        "            # Flipout-estimated bias samples\n",
        "            r = random_rademacher([x.shape[0], self.d_out])\n",
        "            b_samples = tf.nn.softplus(self.b_std)*tf.random.normal([self.d_out])\n",
        "            b_outputs = self.b_loc + r*b_samples\n",
        "            \n",
        "            return w_outputs + b_outputs\n",
        "        \n",
        "        else:\n",
        "            return x @ self.w_loc + self.b_loc\n",
        "    \n",
        "    \n",
        "    @property\n",
        "    def losses(self):\n",
        "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
        "        weight = tfd.Bernoulli(self.w_loc, tf.nn.softplus(self.w_std))\n",
        "        bias = tfd.Bernoulli(self.b_loc, tf.nn.softplus(self.b_std))\n",
        "        prior = tfd.Bernoulli(0, 1)\n",
        "        return (tf.reduce_sum(tfd.kl_divergence(weight, prior)) +\n",
        "                tf.reduce_sum(tfd.kl_divergence(bias, prior)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X69pQAvKzy6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BayesianDenseNetwork(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, dims, name=None):\n",
        "        \n",
        "        super(BayesianDenseNetwork, self).__init__(name=name)\n",
        "        \n",
        "        self.steps = []\n",
        "        self.acts = []\n",
        "        for i in range(len(dims)-1):\n",
        "            self.steps += [BayesianDenseLayer(dims[i], dims[i+1])]\n",
        "            self.acts += [tf.nn.relu]\n",
        "            \n",
        "        self.acts[-1] = lambda x: x\n",
        "        \n",
        "    \n",
        "    def call(self, x, sampling=True):\n",
        "        \"\"\"Perform the forward pass\"\"\"\n",
        "\n",
        "        for i in range(len(self.steps)):\n",
        "            x = self.steps[i](x, sampling=sampling)\n",
        "            x = self.acts[i](x)\n",
        "            \n",
        "        return x\n",
        "    \n",
        "    \n",
        "    @property\n",
        "    def losses(self):\n",
        "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
        "        return tf.reduce_sum([s.losses for s in self.steps])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W-g1HeQqFO_",
        "colab_type": "code",
        "outputId": "94d17d20-2ea8-4f94-b9f7-128548e71e93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class BayesianDenseClassifier(tf.keras.Model):\n",
        "           \n",
        "    def __init__(self, dims, name=None):\n",
        "        \n",
        "        super(BayesianDenseClassifier, self).__init__(name=name)\n",
        "        \n",
        "        # Multilayer fully-connected neural network to predict mean\n",
        "        self.net = BayesianDenseNetwork(dims) #net to predict categorical probs \n",
        "        \n",
        "       \n",
        "    \n",
        "    def call(self, x, sampling=True):\n",
        "        \"\"\"Perform forward pass, predicting both means + stds\"\"\"\n",
        "        logits = self.net(x, sampling = sampling)\n",
        "        return tfd.Bernoulli(logits=logits)\n",
        "        \n",
        "       \n",
        "    \n",
        "    def log_likelihood(self, x, y, sampling=True):\n",
        "        \"\"\"Compute the log likelihood of y given x\"\"\"\n",
        "        return self.call(x, sampling= sampling).log_prob(y)\n",
        "   \n",
        "    @tf.function\n",
        "    def sample(self, x):\n",
        "        \"\"\"Draw one sample from the predictive distribution\"\"\"\n",
        "       \n",
        "        preds = self.call(x)\n",
        "        return tfd.Bernoulli(preds[:,0]).sample()\n",
        "        #return tfd.Bernoulli(preds[:,0], preds[:,1]).sample()\n",
        "    \n",
        "    \n",
        "    def samples(self, x, n_samples=1):\n",
        "        \"\"\"Draw multiple samples from the predictive distribution\"\"\"\n",
        "        samples = np.zeros((x.shape[0], n_samples))\n",
        "        for i in range(n_samples):\n",
        "            samples[:,i] = self.sample(x)\n",
        "        return samples\n",
        "        \n",
        "    @property\n",
        "    def losses(self):\n",
        "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
        "                \n",
        "        # Loss due to network weights\n",
        "        #net_loss = self.loc_net.losses\n",
        "\n",
        "        # Loss due to std deviation parameter\n",
        "        #posterior = tfd.Gamma(self.std_alpha, self.std_beta)\n",
        "        #prior = tfd.Gamma(10.0, 10.0)\n",
        "        #std_loss = tfd.kl_divergence(posterior, prior)\n",
        "\n",
        "        # Return the sum of both\n",
        "        #return net_loss + std_loss\n",
        "        return self.net.losses\n",
        "model1 = BayesianDenseClassifier([4, 32,16,2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-05f9d7acb9c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBayesianDenseClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBayesianDenseClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhQrYCaPpxY4",
        "colab_type": "code",
        "outputId": "6f1f5069-cf2c-4e91-dc31-52135bf81920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "loss_func = tf.keras.losses.BinaryCrossentropy\n",
        "fpr = tf.keras.metrics.FalsePositives()\n",
        "Tpr = tf.keras.metrics.TruePositives()\n",
        "AUC = tf.keras.metrics.AUC()\n",
        "#test_accuracy = tf.keras.metrics.binary_accuracy(y_train, y_pred)\n",
        "#F1_score = tfa.metrics.f_scores.F1Score()\n",
        "# Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(lr=L_RATE)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d711bd5f208e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFalsePositives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTruePositives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi-v4Nt9pxed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = X_train.shape[0]\n",
        "@tf.function\n",
        "def train_step(x_data, y_data):\n",
        "    with tf.GradientTape() as tape:\n",
        "        log_likelihoods = model1.log_likelihood(x_data, y_data)\n",
        "        kl_loss = model1.losses\n",
        "        elbo_loss = kl_loss/N - tf.reduce_mean(log_likelihoods)\n",
        "    gradients = tape.gradient(elbo_loss, model1.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model1.trainable_variables))\n",
        "    return elbo_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJQzbrcxpWRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the model\n",
        "elbo1 = np.zeros(EPOCHS)\n",
        "#mae1 = np.zeros(EPOCHS)\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    # Update weights each batch\n",
        "    for x_data, y_data in train_data:\n",
        "        elbo1[epoch] += train_step(x_data, y_data)\n",
        "        \n",
        "    # Evaluate performance on validation data\n",
        "    for x_data, y_data in test_data:\n",
        "        y_pred = model1(x_data).mode()\n",
        "        #mae1[epoch] = mean_absolute_error(y_pred, y_data)\n",
        "        test_accuracy(y_pred, y_data)\n",
        "        print(\"step: %i, loss: %f, accuraccy: :%f\" %(step, loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWMc7ku2pWdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the ELBO loss\n",
        "plt.plot(elbo1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('ELBO Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2J7zh3UpWgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot validation error over training\n",
        "plt.plot(mae1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80qX7-UN7aDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}